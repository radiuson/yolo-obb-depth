{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5773a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def autopad(k, p=None):\n",
    "    return k // 2 if p is None else p\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, c1, c2, k=3, s=1, p=None):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = nn.ReLU6(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class DepthHead(nn.Module):\n",
    "    \"\"\"Depth head with multi-scale inverse depth output (1 channel per head)\"\"\"\n",
    "\n",
    "    def __init__(self, ch=()):\n",
    "        super().__init__()\n",
    "        self.nl = len(ch)  # number of input feature maps\n",
    "        self.stride = torch.zeros(self.nl)\n",
    "\n",
    "        c2 = max(16, ch[0] // 4)  # intermediate channels\n",
    "\n",
    "        # 创建每层的 Conv 结构（Conv → Conv → 1x1 输出 1 通道）\n",
    "        self.cv2 = nn.ModuleList([Conv(c, c2, 3) for c in ch])\n",
    "        self.cv3 = nn.ModuleList([Conv(c2, c2, 3) for _ in ch])\n",
    "        self.cv4 = nn.ModuleList([nn.Conv2d(c2, 1, 1) for _ in ch])  # 每层输出 1 通道\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"x: list of feature maps\"\"\"\n",
    "        out = [None] * self.nl\n",
    "        for i in range(self.nl):\n",
    "            if i ==0:\n",
    "                feat = self.cv2[i](x[i])\n",
    "                feat = self.cv3[i](feat)\n",
    "                up_feat = F.interpolate(feat, size=x[i + 1].shape[2:], mode='nearest')\n",
    "                x[i + 1] = self.cv2[i+1](x[i + 1]) + up_feat\n",
    "            elif i == self.nl - 1:\n",
    "                feat = self.cv3[i](feat)\n",
    "            else:\n",
    "                feat = self.cv3[i](x[i])\n",
    "                up_feat = F.interpolate(feat, size=x[i + 1].shape[2:], mode='nearest')\n",
    "                x[i + 1] = self.cv2[i+1](x[i + 1]) + up_feat\n",
    "\n",
    "            depth = self.cv4[i](feat)        # 输出为 B×1×H×W\n",
    "            inv_depth = 1.0 / (depth + 1e-6)  # 计算 inverse depth\n",
    "            out[i] = inv_depth\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84686d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DepthHead' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mDepthHead\u001b[49m(ch=[\u001b[32m64\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m64\u001b[39m])\n\u001b[32m      2\u001b[39m x = [torch.randn(\u001b[32m1\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m80\u001b[39m, \u001b[32m80\u001b[39m),\n\u001b[32m      3\u001b[39m      torch.randn(\u001b[32m1\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m40\u001b[39m, \u001b[32m40\u001b[39m),\n\u001b[32m      4\u001b[39m      torch.randn(\u001b[32m1\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m20\u001b[39m)]\n\u001b[32m      6\u001b[39m y = model(x)\n",
      "\u001b[31mNameError\u001b[39m: name 'DepthHead' is not defined"
     ]
    }
   ],
   "source": [
    "model = DepthHead(ch=[64, 64, 64])\n",
    "x = [torch.randn(1, 64, 80, 80),\n",
    "     torch.randn(1, 64, 40, 40),\n",
    "     torch.randn(1, 64, 20, 20)]\n",
    "\n",
    "y = model(x)\n",
    "for d in y:\n",
    "    print(d.shape)  # → torch.Size([1, 1, H, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = np.zeros((300, 300, 3), dtype=np.uint8)\n",
    "cv2.imshow(\"test\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
